{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "public-stroke",
   "metadata": {},
   "source": [
    "# RawMSA test implementation\n",
    "\n",
    "In this notebook I test my implementation of the rawMSA net for the prediction of secondary structure and solvent accessibility (its original tasks). I will in other notebooks adapt the net for the prediction of variant effect. I am using the very limited grey2018 dataset with 9 proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "technological-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_full = pd.read_csv('../dataset/gray2018/dmsTraining_2017-02-20.csv')\n",
    "df = df_full\n",
    "\n",
    "# some of the studies in the training set were excluded from training in the original paper\n",
    "excluded_studies = ['Brca1_E3', 'Brca1_Y2H', 'E3_ligase']\n",
    "for study in excluded_studies:\n",
    "    df = df[df['dms_id'] != study]\n",
    "    \n",
    "# many of the columns are not needed for this task\n",
    "df = df[['uniprot_id', 'position', 'dssp_sec_str', 'accessibility']]\n",
    "\n",
    "# for this task I don't care about different mutations in the same position, I want each position only once\n",
    "# I can drop duplicates since I removed all the columns relating to the kind of mutatiion\n",
    "df = df.drop_duplicates()\n",
    "    \n",
    "# boolean vectors to slice the rows which have a value\n",
    "has_dssp = df['dssp_sec_str'].notna()\n",
    "has_accessibility = df['accessibility'].notna()\n",
    "\n",
    "df_dssp = df[has_dssp]\n",
    "df_accessibility = df[has_accessibility]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-communication",
   "metadata": {},
   "source": [
    "## Extracting the secondary structures and accessibility\n",
    "\n",
    "Many sequence positions have an annotated dssp secondary structure and solvent accessibility in the Gray2018 dataset. Here I extract it and put it into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "consecutive-carpet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../processing/raw_msa/implementation_test_grey2018/accessibility_labels.np.joblib.xz']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_rawmsa_test_path = '../processing/raw_msa/implementation_test_grey2018/'\n",
    "\n",
    "# 3 class dssp mapping reduction\n",
    "ss_d = {\n",
    "        \"H\": \"H\",\n",
    "        \"B\": \"E\",\n",
    "        \"E\": \"E\",\n",
    "        \"G\": \"-\",\n",
    "        \"I\": \"-\",\n",
    "        \"T\": \"-\",\n",
    "        \"S\": \"-\",\n",
    "        \".\": \"-\", # should be a space but it was replaced by . in the grey dataset\n",
    "    }\n",
    "# need to code each class with an integer\n",
    "ss_sparse = {\n",
    "        \"H\": 0,\n",
    "        \"E\": 1,\n",
    "        \"-\": 2,\n",
    "    }\n",
    "ss_list = [ss_sparse[ss_d[el]] for el in df['dssp_sec_str'][has_dssp]]\n",
    "\n",
    "# creating and saving the label arrays\n",
    "ss_array = np.array(ss_list).reshape(-1,1)\n",
    "accessibility_array = np.array(df['accessibility'][has_accessibility]).reshape(-1,1)\n",
    "joblib.dump(ss_array, out_rawmsa_test_path + 'ss_labels.np.joblib.xz')\n",
    "joblib.dump(accessibility_array, out_rawmsa_test_path + 'accessibility_labels.np.joblib.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-method",
   "metadata": {},
   "source": [
    "## Obtaining sliding windows\n",
    "\n",
    "For each of the position in the msa of the proteins in the dataset, I obtain the relative sliding window padded with 0 if needed at the right, left or bottom. I put it in a lookup table for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "certified-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 31\n",
    "msa_depth = 500\n",
    "in_msa_path = '../processing/gray2018/msa_vectors/'\n",
    "basename_list = '../processing/gray2018/input_list.txt'\n",
    "\n",
    "with open(basename_list) as handle:\n",
    "    sliding_windows = {}\n",
    "    for line in handle:\n",
    "        basename = line.rstrip()\n",
    "        msa_vec = joblib.load(in_msa_path + basename + '.npy.joblib.xz')[:msa_depth]\n",
    "        windows_list = []\n",
    "        for i, _ in enumerate(msa_vec.T):\n",
    "            upper = i + ((window_size - 1)//2) + 1\n",
    "            lower = i - ((window_size - 1)//2)\n",
    "            pad_lower, pad_upper = 0, 0\n",
    "            if lower < 0:\n",
    "                pad_lower = - lower\n",
    "                lower = 0\n",
    "            if upper > len(msa_vec.T):\n",
    "                pad_upper = upper - len(msa_vec.T)\n",
    "                # no need to reset upper since numpy allows indeces exceeding len\n",
    "            curr_window_unpadded = msa_vec[:, lower:upper]\n",
    "            # this is for the vertical padding if there are not enough sequences in the msa\n",
    "            pad_vertical = 0\n",
    "            if len(msa_vec) < msa_depth:\n",
    "                pad_vertical = msa_depth - len(msa_vec)\n",
    "            # 0 is a special padding value for the keras embedding layer\n",
    "            curr_window = np.pad(curr_window_unpadded, ((0,pad_vertical),(pad_lower,pad_upper)), mode='constant', constant_values = 0)\n",
    "            assert curr_window.shape == (msa_depth, window_size)\n",
    "            windows_list.append(curr_window)\n",
    "        sliding_windows[basename] = np.array(windows_list)\n",
    "        assert sliding_windows[basename].shape == (len(msa_vec.T), msa_depth, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-plaintiff",
   "metadata": {},
   "source": [
    "## Map the sliding windows to the training data\n",
    "\n",
    "For each training point, I extract the relative sliding window and I put it into a vector that can be used for training together with the ss and accessibility vectors. I save the output to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "absent-variance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../processing/raw_msa/implementation_test_grey2018/accessibility_sliding_window.np.joblib.xz']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_windows(sliding_windows, df):\n",
    "    # the first element of iterrows is the index\n",
    "    windows = []\n",
    "    for _, row in df.iterrows():\n",
    "        # I remove 1 to position since the index starts from 0 but the position from 1\n",
    "        curr_window = sliding_windows[row['uniprot_id']][row['position']-1]\n",
    "        windows.append(curr_window)\n",
    "    windows_vec = np.array(windows)\n",
    "    assert windows_vec.shape[0] == len(df)\n",
    "    return windows_vec\n",
    "\n",
    "dssp_windows = map_windows(sliding_windows, df_dssp)\n",
    "accessibility_windows = map_windows(sliding_windows, df_accessibility)\n",
    "\n",
    "joblib.dump(dssp_windows, '../processing/raw_msa/implementation_test_grey2018/ss_sliding_window.np.joblib.xz')\n",
    "joblib.dump(accessibility_windows, '../processing/raw_msa/implementation_test_grey2018/accessibility_sliding_window.np.joblib.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-cartridge",
   "metadata": {},
   "source": [
    "## Deep learning\n",
    "\n",
    "Here general operation that are common to all the deep learning steps, and I show tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "presidential-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "import sklearn.metrics\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "overall-updating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 227810), started 0:24:31 ago. (Use '!kill 227810' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d6172057ea44441\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d6172057ea44441\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-sydney",
   "metadata": {},
   "source": [
    "### SS network\n",
    "\n",
    "Here I create the rawMSA network for secondary structure prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "active-series",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my input is of shape LY where L is the size of the sliding window (31 here) and Y is the depth (500 here)\n",
    "# In this original implementation the input is a vector, so I presume that they first flatten the msa to give as input\n",
    "# this is not really declared anywhere but if I give in input a None,None shape, then the reshape removes a dimension!\n",
    "# the dimensions declared here do not include the batch size, which is added as a None first dimension automatically\n",
    "# note that this is a tensor shape, not an input layer\n",
    "# for the functional API is recommended in place of InputLayer\n",
    "window_size = 31\n",
    "msa_depth = 500\n",
    "embedding_dim = 14\n",
    "inputs = tf.keras.Input(shape=(msa_depth, window_size))\n",
    "# I flatten the input for the embedding layer\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# this is the embedding layer\n",
    "# 26 is the number of residues (20 standard, the additional characthers XBZU, and - for gaps)\n",
    "# 14 is the dimensionality of the embedding used\n",
    "# I am avoiding here to specify many parameters, if the defaults differ from what is in the rawMSA paper I will adjust it later\n",
    "# x is the running variable that I use to connect the layers\n",
    "# the shape after the embedding is batch,LY,E\n",
    "x = tf.keras.layers.Embedding(input_dim=26, output_dim=embedding_dim, mask_zero=True)(x)\n",
    "# I reshape to undo the initial flattening of the input, so I separate the L and Y dimensions (length and alignment depth)\n",
    "# my shape now is batch,L,Y,E\n",
    "x = tf.keras.layers.Reshape((-1,msa_depth,embedding_dim))(x)\n",
    "# for the ss_rsa netowork there is a single convolution on the embedded input\n",
    "# I use a number of filters equal to the embedding dimensionality\n",
    "# the filter is still of width 1 but much longer than the one used for the cmap network\n",
    "# the activation is linear since there is a separate relu activation layer\n",
    "# the dimensions do not change after this layers but from now on I will refer to the third axis as F and not E\n",
    "x = tf.keras.layers.Conv2D(embedding_dim, [1,10], activation='relu', padding='same', data_format='channels_last')(x)\n",
    "# this max pooling layer uses a really long pooling but always of 1 column width\n",
    "# this compresses the Y dimension\n",
    "# the shape goes from batch,L,Y,F to batch,L,S,F, where S=Y/n is 500/20=25\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=[1,20], data_format='channels_last')(x)\n",
    "# I remove 1 axis by concatenating S and F to SF where SF=25*14=350\n",
    "# the new shape is batch,L,SF\n",
    "x = tf.keras.layers.Reshape((-1,embedding_dim*(msa_depth//20)))(x)\n",
    "# the last part of the network involves bidirectional LSTM units\n",
    "# the sequence is read with recurrent units in both direction and then the results are averaged (merge_mode='ave')\n",
    "# I want in output a full sequence and not only the last output of the recurrence\n",
    "# It uses tanh activation in output but hard sigmoid between the recurrent units\n",
    "# the hard sigmoid is a piecewise function with similar behaviour to the sigmoid\n",
    "# it is easier to compute at the cost of precision\n",
    "# the initializtion default is glorot while the authors used variance scaling\n",
    "# I leave it glorot for now since I believe it to be due to the keras version default\n",
    "# the lstm_brnn + droput combination is applied twice\n",
    "# this loop does not alter the shape (it is a seq-to-seq lstm) which remains batch,L,SF=350\n",
    "for _ in range(2):\n",
    "    lstm_layer = tf.keras.layers.LSTM(embedding_dim*(msa_depth//20), return_sequences=True, recurrent_activation='hard_sigmoid')\n",
    "    x = tf.keras.layers.Bidirectional(lstm_layer, merge_mode='ave')(x)\n",
    "    # dropout layer with a 0.5 probability of dropping a connection\n",
    "    # non-dropped input are rescaled so to maintain the some over the inputs\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "# the L and SF axes are collapsed, giving dimension batch,LSF\n",
    "# I am concatenating the sliding window dimension L with the depth/channel dimension SF\n",
    "x = tf.keras.layers.Flatten(data_format='channels_last')(x)\n",
    "# now 2 dense layers with dropout to convert all the information to 3 values, the prediction for the\n",
    "# ss of the central residue of the sliding window\n",
    "x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(20, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "# finally softmax with 3 output units for the 3 ss classes for the central residue\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "# I generate the model linking inputs and outputs\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='ss_recreated')\n",
    "# the optimizer is RMSProp with a tweaked epsilon\n",
    "optimizer = tf.keras.optimizers.RMSprop(epsilon=1e-9)\n",
    "# the loss is sparse_categorical_crossentropy (a function), not the class SparseCategoricalCrossentropy\n",
    "# when using the class it needs to be called first\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "q3_accuracy = sklearn.metrics.accuracy_score\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "royal-survivor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 23s 700ms/step - loss: 1.1505 - sparse_categorical_accuracy: 0.3283 - val_loss: 1.2595 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 16s 654ms/step - loss: 1.0950 - sparse_categorical_accuracy: 0.4433 - val_loss: 1.1418 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 17s 691ms/step - loss: 1.0480 - sparse_categorical_accuracy: 0.4625 - val_loss: 1.0429 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 16s 674ms/step - loss: 0.9729 - sparse_categorical_accuracy: 0.5166 - val_loss: 1.1151 - val_sparse_categorical_accuracy: 0.3789\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 16s 670ms/step - loss: 0.9401 - sparse_categorical_accuracy: 0.5258 - val_loss: 1.0143 - val_sparse_categorical_accuracy: 0.4368\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 16s 668ms/step - loss: 0.8548 - sparse_categorical_accuracy: 0.5796 - val_loss: 1.1037 - val_sparse_categorical_accuracy: 0.3579\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 16s 679ms/step - loss: 0.8240 - sparse_categorical_accuracy: 0.5987 - val_loss: 2.3017 - val_sparse_categorical_accuracy: 0.2316\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 16s 681ms/step - loss: 0.9211 - sparse_categorical_accuracy: 0.5967 - val_loss: 1.2903 - val_sparse_categorical_accuracy: 0.3526\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 16s 671ms/step - loss: 0.7480 - sparse_categorical_accuracy: 0.6407 - val_loss: 1.2930 - val_sparse_categorical_accuracy: 0.4789\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 16s 670ms/step - loss: 0.7457 - sparse_categorical_accuracy: 0.6532 - val_loss: 1.1003 - val_sparse_categorical_accuracy: 0.4737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff48de37130>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input selection\n",
    "x = joblib.load('../processing/raw_msa/implementation_test_grey2018/ss_sliding_window.np.joblib.xz')\n",
    "y = joblib.load('../processing/raw_msa/implementation_test_grey2018/ss_labels.np.joblib.xz')\n",
    "#np.random.shuffle(y)\n",
    "\n",
    "# tensorflow logging\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# fit the model\n",
    "model.fit(x, y, epochs=10, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-arkansas",
   "metadata": {},
   "source": [
    "### RSA network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dominant-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to ss network but with different embedding dim, conv2d kernel size, max_pool size, droput\n",
    "\n",
    "window_size = 31\n",
    "msa_depth = 500\n",
    "embedding_dim = 28\n",
    "\n",
    "inputs = tf.keras.Input(shape=(msa_depth, window_size))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Embedding(input_dim=26, output_dim=embedding_dim, mask_zero=True)(x)\n",
    "x = tf.keras.layers.Reshape((-1,msa_depth,embedding_dim))(x)\n",
    "x = tf.keras.layers.Conv2D(embedding_dim, [1,20], activation='relu', padding='same', data_format='channels_last')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=[1,30], data_format='channels_last')(x)\n",
    "x = tf.keras.layers.Reshape((-1,embedding_dim*(msa_depth//30)))(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    lstm_layer = tf.keras.layers.LSTM(embedding_dim*(msa_depth//30), return_sequences=True, recurrent_activation='hard_sigmoid')\n",
    "    x = tf.keras.layers.Bidirectional(lstm_layer, merge_mode='ave')(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten(data_format='channels_last')(x)\n",
    "x = tf.keras.layers.Dense(50)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(20)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='rsa_recreated')\n",
    "optimizer = tf.keras.optimizers.RMSprop(epsilon=1e-9)\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "q3_accuracy = sklearn.metrics.accuracy_score\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imposed-belle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 43s 2s/step - loss: 1.0818 - sparse_categorical_accuracy: 0.0111 - val_loss: 0.0461 - val_sparse_categorical_accuracy: 0.0753\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 36s 1s/step - loss: 0.0967 - sparse_categorical_accuracy: 0.0254 - val_loss: 0.0385 - val_sparse_categorical_accuracy: 0.0753\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 36s 1s/step - loss: 0.0838 - sparse_categorical_accuracy: 0.0387 - val_loss: 0.0374 - val_sparse_categorical_accuracy: 0.0753\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 36s 1s/step - loss: 0.1061 - sparse_categorical_accuracy: 0.0361 - val_loss: 0.0902 - val_sparse_categorical_accuracy: 0.0753\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 36s 1s/step - loss: 0.1109 - sparse_categorical_accuracy: 0.0208 - val_loss: 0.0400 - val_sparse_categorical_accuracy: 0.0753\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 36s 2s/step - loss: 0.0966 - sparse_categorical_accuracy: 0.0324 - val_loss: 0.0524 - val_sparse_categorical_accuracy: 0.0753\n",
      "Epoch 7/10\n",
      " 2/24 [=>............................] - ETA: 31s - loss: 0.1047 - sparse_categorical_accuracy: 0.0234"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ce584c8fa90e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# fit the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tf2.4_env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.4_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.4_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.4_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.4_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/tf2.4_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2.4_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# input selection\n",
    "x = joblib.load('../processing/raw_msa/implementation_test_grey2018/accessibility_sliding_window.np.joblib.xz')\n",
    "y_cont = joblib.load('../processing/raw_msa/implementation_test_grey2018/accessibility_labels.np.joblib.xz')\n",
    "y = np.array([1 if el > 0.3 else 0 for el in y_cont])\n",
    "#np.random.shuffle(y)\n",
    "\n",
    "# tensorflow logging\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# fit the model\n",
    "model.fit(x, y_cont, epochs=10, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-attempt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
