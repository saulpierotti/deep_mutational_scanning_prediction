{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "global-attack",
   "metadata": {},
   "source": [
    "# PsiBLAST processing\n",
    "\n",
    "This notebook is to extract profiles with psiblast from each of the sequences in the training set. I am using psiblast from the official linux distribution at the NCBI website:\n",
    "\n",
    "`ncbi-blast-2.11.0+-x64-linux.tar.gz`\n",
    "\n",
    "Here there are the already-compiled executables. There is a script in the package, `update_blastdb.pl` that I use to download the databases with this synthax:\n",
    "\n",
    "`./update_blastdb.pl --decompress <database>`\n",
    "\n",
    "To see available databases run:\n",
    "\n",
    "`./update_blastdb.pl --showall`\n",
    "\n",
    "For this project I am using the database `nr`, but I also downloaded `swissprot` since it is much smaller and I did not have enough space initially. The size of swissprot is some GB, the size of nr is around 300 GB decompressed. There is no need to use `makebalstdb` on the databases downloaded with `update_blastdb.pl` since they are already in an usable format. The run of psiblast on nr is quite heavy and thus I am running it on the server aeserv19a. Simple file movements are omitted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "concerned-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "in_path = '../processing/input_sequences/'\n",
    "input_list_file = '../processing/input_list.txt'\n",
    "seq_json_file = '../dataset/Reeb2020/sequences.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-trademark",
   "metadata": {},
   "source": [
    "I create a series of fasta files with all the sequences in the Rebb2020 set named in a similar way to how dataset are referenced in the csv of the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "veterinary-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_seqs_filein = open(seq_json_file)\n",
    "json_seqs_dict = json.load(json_seqs_filein)\n",
    "for paper in json_seqs_dict:\n",
    "    for dms_set in json_seqs_dict[paper]:\n",
    "        with open(in_path + paper + '-' + dms_set + '.fasta', 'w') as fastaout:\n",
    "            fastaout.write('>' + paper + '/' + dms_set + '\\n' + json_seqs_dict[paper][dms_set] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-mayor",
   "metadata": {},
   "source": [
    "I put the fasta basenames in a file for easier handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "changing-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $in_path | cut -d '.' -f '1' > $input_list_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-monitoring",
   "metadata": {},
   "source": [
    "Run this only if you want to process the swissprot pssm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "embedded-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ckp_path = '../processing/psiblast_processing/swissprot_db/ckp_files/'\n",
    "out_profile_path = '../processing/psiblast_processing/swissprot_db/profiles/'\n",
    "out_pssm_path = '../processing/psiblast_processing/swissprot_db/pssm_array/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-bandwidth",
   "metadata": {},
   "source": [
    "Run this only if you want to process the nr pssm files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "quiet-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_ckp_path = '../processing/psiblast_processing/nr_db/ckp_files/'\n",
    "out_profile_path = '../processing/psiblast_processing/nr_db/profiles/'\n",
    "out_pssm_path = '../processing/psiblast_processing/nr_db/pssm_array/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-phenomenon",
   "metadata": {},
   "source": [
    "I run psiblast from a wrapper script:\n",
    "\n",
    "`./psiblast_wrapper.sh <list of fasta files> <database>`\n",
    "\n",
    "This is very heavy and I do it on the server, not on the notebook. The parameters used are:\n",
    "\n",
    "- E value reporting threshold of 0.01\n",
    "- 3 iterations\n",
    "- I want the pssm matrices in output\n",
    "\n",
    "After putting the pssm files in the appropriate folder, I obtain the profiles and I save them in .npy files. The first columns of the file are the pssm, while the profile is in the second half. I also move the resulting .npy files in the appropriate folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tight-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profile(checkpoint_file):\n",
    "    \"\"\"\n",
    "    Extract the profile portion from a single-sequence psiblast checkpoint\n",
    "    file and returns it as a numpy array.\n",
    "    \"\"\"\n",
    "    ckp = []\n",
    "    header = True\n",
    "    footer = False\n",
    "    with open(checkpoint_file) as handle:\n",
    "        for line in handle:\n",
    "            line_l = line.rstrip().split()\n",
    "\n",
    "            if len(line_l) > 0 and line_l[0] == \"1\":\n",
    "                header = False\n",
    "\n",
    "            if not header and len(line_l) == 0:\n",
    "                footer = True\n",
    "\n",
    "            if not header and not footer:\n",
    "                # select only the profile and discard the pssm\n",
    "                # and the last 2 columns\n",
    "                ckp.append([float(el) for el in line_l[22:-2]])\n",
    "    ckp_mat = np.array(ckp)\n",
    "\n",
    "    profile = ckp_mat / 100\n",
    "    \n",
    "    return profile\n",
    "\n",
    "\n",
    "def get_pssm(checkpoint_file):\n",
    "    \"\"\"\n",
    "    Extract the profile portion from a single-sequence psiblast checkpoint\n",
    "    file and returns it as a numpy array.\n",
    "    \"\"\"\n",
    "    pssm = []\n",
    "    header = True\n",
    "    footer = False\n",
    "    with open(checkpoint_file) as handle:\n",
    "        for line in handle:\n",
    "            line_l = line.rstrip().split()\n",
    "\n",
    "            if len(line_l) > 0 and line_l[0] == \"1\":\n",
    "                header = False\n",
    "\n",
    "            if not header and len(line_l) == 0:\n",
    "                footer = True\n",
    "\n",
    "            if not header and not footer:\n",
    "                # select only the pssm and discard the profile\n",
    "                pssm.append([int(el) for el in line_l[2:22]])\n",
    "    pssm_mat = np.array(pssm)\n",
    "    \n",
    "    # no normalization done, could be revisited later\n",
    "    \n",
    "    return pssm_mat\n",
    "\n",
    "with open(input_list_file) as handle:\n",
    "    for line in handle:\n",
    "        curr_header = line.rstrip()\n",
    "        ckp_file = in_ckp_path + curr_header + '.psiblast.ckp'\n",
    "        profile_outfile = out_profile_path + curr_header + '.profile.npy'\n",
    "        pssm_outfile = out_pssm_path + curr_header + '.pssm.npy'\n",
    "        curr_profile, curr_pssm = get_profile(ckp_file), get_pssm(ckp_file)\n",
    "        np.save(profile_outfile, curr_profile)\n",
    "        np.save(pssm_outfile, curr_pssm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-theory",
   "metadata": {},
   "source": [
    "Now all the profiles are stored in numpy arrays and ready for further processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
