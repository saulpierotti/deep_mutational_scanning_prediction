{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "everyday-margin",
   "metadata": {},
   "source": [
    "# MNIST neural network\n",
    "\n",
    "Here I use the MINST dataset to practice with neural networks\n",
    "\n",
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imperial-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000, 28, 28, 1), (60000,), (60000,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANR0lEQVR4nO3dbYxc5XnG8evC+KW209SGxnWNWztgUll9ccjKKYESUtSImA+GFtG4auSolE2lIJEKpVBSCbf9UBQ1oahJIy3FxWkIUSJA+INF4jppARFZXoiL3wqmjile2V4DVTGUGnv37oc9jhZ75+zunDNzJr7/P2k1M+eemXNz4OK8PDPzOCIE4Nx3XtMNAOgOwg4kQdiBJAg7kARhB5I4v5srm+XZMUfzurlKIJX/01t6J054olqlsNu+VtJ9kmZI+seIuKfs+XM0Tx/2NVVWCaDE9tjWstb2YbztGZK+KukTklZKWmd7ZbvvB6Czqpyzr5b0UkQciIh3JH1L0tp62gJQtyphXyLplXGPDxXL3sV2v+1B24MndaLC6gBU0fGr8RExEBF9EdE3U7M7vToALVQJ+5CkpeMeX1QsA9CDqoR9h6QVtpfbniXpk5I219MWgLq1PfQWEads3yrpuxobetsYEXtq6wxArSqNs0fEFklbauoFQAfxcVkgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSqDSLK1DFa7dcXlrfvuGrpfVV991aWv/FLz4z7Z7OZZXCbvugpOOSRiSdioi+OpoCUL869uwfi4hXa3gfAB3EOTuQRNWwh6Tv2X7Wdv9ET7Ddb3vQ9uBJnai4OgDtqnoYf2VEDNl+n6Sttv8jIp4c/4SIGJA0IEk/64VRcX0A2lRpzx4RQ8XtsKTHJK2uoykA9Ws77Lbn2X7P6fuSPi5pd12NAahXlcP4RZIes336fb4ZEU/U0hVSmHvjkdL6qMrP+k4s4KxwOtoOe0QckPQbNfYCoIMYegOSIOxAEoQdSIKwA0kQdiAJvuKKjpqx8tKWtUdX/lPpa/9i+IrS+iUPHiutj5RW82HPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7eC8a+Jty+6N2veu770/e2rL33vDmlr/3+UOsxekla+MKLbfWUFXt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfYe8Nbvls+tsebufy2tb/2zq1rWZj2xo52WavOhX/lx26/9n90XlNYXtv3OObFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkGGfvAef/72hp/fMX7C2tP/jR325ZW97hSbRnXHpxaf2B5d9oWfvxqfJ/7hUDh0vrp0qrONOke3bbG20P2949btlC21tt7y9uF3S2TQBVTeUw/kFJ156x7E5J2yJihaRtxWMAPWzSsEfEk5JeP2PxWkmbivubJF1fb1sA6tbuOfuiiDh9QnVE0qJWT7TdL6lfkuZobpurA1BV5avxERGSWv7iYUQMRERfRPTN1OyqqwPQpnbDftT2YkkqbofrawlAJ7Qb9s2S1hf310t6vJ52AHTKpOfsth+WdLWkC20fknS3pHskfdv2zZJelnRTJ5s81/3M0PGmW2jbwd9veblGkjTfrU/dvjB8eelrTx042E5LaGHSsEfEuhala2ruBUAH8XFZIAnCDiRB2IEkCDuQBGEHkuArrj3gxPvmNd1C295e3P4XTbdsX1VaX6Htbb83zsaeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJy9Bxy8vvxfw3lylzo524wV7y+tf/e6e8tf79afIfjA/W+Uvrb8h6YxXezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtm74Ly55dNefee6vy+tj2pGaf3T132/ZW3jL32k9LULf+7N0vofLX+mtL78/Dml9b88trJlbXTXi6WvRb3YswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzd8HQn6wqrf/6rKcqvf/nL9jbsnbH1ftKXzuqqLTuyWz+h4+2rF04+sOOrhvvNume3fZG28O2d49btsH2kO2dxd+azrYJoKqpHMY/KOnaCZbfGxGrir8t9bYFoG6Thj0inpT0ehd6AdBBVS7Q3Wr7+eIwf0GrJ9nutz1oe/CkTlRYHYAq2g371yRdLGmVpMOSvtTqiRExEBF9EdE3U7PbXB2AqtoKe0QcjYiRiBiVdL+k1fW2BaBubYXd9uJxD2+QtLvVcwH0hknH2W0/LOlqSRfaPiTpbklX214lKSQdlPSZzrX40++ty94urR8dKa//1rbbSuszj8xqWZv93+W/OT/7tfJx9h/+1VdK65NZ9Ejr76yPVHpnTNekYY+IdRMsfqADvQDoID4uCyRB2IEkCDuQBGEHkiDsQBJ8xbULLvnDH5XWb9aVpfVL9Wyd7bzLa7dcXlqfbLroq3bdWFqf/+qBafeEzmDPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM6e3Nwbj5TWJ/up6WM/WlRany/G2XsFe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9uS+8oGHS+ujmlFaX/Jvp+psBx3Enh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCc/Rw38rHLSuvz/HRp/ff231Ban/XEjmn3hGZMume3vdT2D2zvtb3H9m3F8oW2t9reX9wu6Hy7ANo1lcP4U5Juj4iVkn5T0mdtr5R0p6RtEbFC0rbiMYAeNWnYI+JwRDxX3D8uaZ+kJZLWStpUPG2TpOs71COAGkzrnN32MkkflLRd0qKIOFyUjkia8MfIbPdL6pekOZrbdqMAqpny1Xjb8yU9IulzEfHG+FpEhDTxLxNGxEBE9EVE30zNrtQsgPZNKey2Z2os6A9FxKPF4qO2Fxf1xZKGO9MigDpMehhv25IekLQvIr48rrRZ0npJ9xS3j3ekQ1Sy8K9fLq0vO7/81OqhSx4trX/kz28vrV/0N8+U1tE9Uzlnv0LSpyTtsr2zWHaXxkL+bds3S3pZ0k0d6RBALSYNe0Q8LcktytfU2w6ATuHjskAShB1IgrADSRB2IAnCDiTBV1zPcaPRaiClqE8yJfPfvfah0vqyb/xXaZ0fmu4d7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2c9xf7z4qdL6oVNvl9a3/8GvldZHXnlh2j2hGezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtnPcb8w443S+lNvLyutj+xhHP1cwZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5KYyvzsSyV9XdIiSSFpICLus71B0i2SjhVPvSsitnSqUbTnjuUfbroF9IipfKjmlKTbI+I52++R9KztrUXt3oj42861B6AuU5mf/bCkw8X947b3SVrS6cYA1Gta5+y2l0n6oKTtxaJbbT9ve6PtBS1e02970PbgSZ2o1i2Atk057LbnS3pE0uci4g1JX5N0saRVGtvzf2mi10XEQET0RUTfTM2u3jGAtkwp7LZnaizoD0XEo5IUEUcjYiQiRiXdL2l159oEUNWkYbdtSQ9I2hcRXx63fPG4p90gaXf97QGoy1Suxl8h6VOSdtneWSy7S9I626s0Nhx3UNJnOtAfgJpM5Wr805ImmuSbMXXgpwifoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiThiOjeyuxjkl4et+hCSa92rYHp6dXeerUvid7aVWdvvxwRPz9RoathP2vl9mBE9DXWQIle7a1X+5LorV3d6o3DeCAJwg4k0XTYBxpef5le7a1X+5LorV1d6a3Rc3YA3dP0nh1AlxB2IIlGwm77Wtsv2H7J9p1N9NCK7YO2d9neaXuw4V422h62vXvcsoW2t9reX9xOOMdeQ71tsD1UbLudttc01NtS2z+wvdf2Htu3Fcsb3XYlfXVlu3X9nN32DEkvSvodSYck7ZC0LiL2drWRFmwflNQXEY1/AMP2VZLelPT1iPjVYtkXJb0eEfcU/6NcEBF39EhvGyS92fQ03sVsRYvHTzMu6XpJn1aD266kr5vUhe3WxJ59taSXIuJARLwj6VuS1jbQR8+LiCclvX7G4rWSNhX3N2nsP5aua9FbT4iIwxHxXHH/uKTT04w3uu1K+uqKJsK+RNIr4x4fUm/N9x6Svmf7Wdv9TTczgUURcbi4f0TSoiabmcCk03h30xnTjPfMtmtn+vOquEB3tisj4jJJn5D02eJwtSfF2DlYL42dTmka726ZYJrxn2hy27U7/XlVTYR9SNLScY8vKpb1hIgYKm6HJT2m3puK+ujpGXSL2+GG+/mJXprGe6JpxtUD267J6c+bCPsOSStsL7c9S9InJW1uoI+z2J5XXDiR7XmSPq7em4p6s6T1xf31kh5vsJd36ZVpvFtNM66Gt13j059HRNf/JK3R2BX5/5T0hSZ6aNHX+yX9e/G3p+neJD2sscO6kxq7tnGzpAskbZO0X9K/SFrYQ739s6Rdkp7XWLAWN9TblRo7RH9e0s7ib03T266kr65sNz4uCyTBBTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSOL/AQtN3GMw0EUOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tfds.image_classification.MNIST().download_and_prepare()\n",
    "dataset = tfds.image_classification.MNIST().as_dataset()\n",
    "train_list = list(dataset['train'].as_numpy_iterator())\n",
    "x_train, y_train = np.array([item['image'] for item in train_list]), np.array([item['label'] for item in train_list])\n",
    "test_list = list(dataset['train'].as_numpy_iterator())\n",
    "x_test, y_test = np.array([item['image'] for item in train_list]), np.array([item['label'] for item in test_list])\n",
    "x_train_norm = x_train / 255\n",
    "x_test_norm = x_test / 255\n",
    "plt.imshow(np.squeeze(x_train_norm[0]))\n",
    "\n",
    "x_train_norm.shape, x_test_norm.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-dream",
   "metadata": {},
   "source": [
    "## Vanilla MLP without normalization\n",
    "\n",
    "Without normalizing the scores are quite bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rotary-chemistry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 10.4271 - sparse_categorical_accuracy: 0.3584 - val_loss: 2.3421 - val_sparse_categorical_accuracy: 0.0981\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4685 - sparse_categorical_accuracy: 0.5126 - val_loss: 2.4262 - val_sparse_categorical_accuracy: 0.0976\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.1859 - sparse_categorical_accuracy: 0.6093 - val_loss: 2.4983 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.9601 - sparse_categorical_accuracy: 0.6966 - val_loss: 2.5753 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.8094 - sparse_categorical_accuracy: 0.7448 - val_loss: 2.5979 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.7514 - sparse_categorical_accuracy: 0.7643 - val_loss: 2.6359 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6978 - sparse_categorical_accuracy: 0.7835 - val_loss: 2.6327 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6735 - sparse_categorical_accuracy: 0.7987 - val_loss: 2.6092 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6541 - sparse_categorical_accuracy: 0.8071 - val_loss: 2.6394 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6185 - sparse_categorical_accuracy: 0.8204 - val_loss: 2.5654 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.6108 - sparse_categorical_accuracy: 0.8231 - val_loss: 2.5603 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5972 - sparse_categorical_accuracy: 0.8314 - val_loss: 2.5373 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5821 - sparse_categorical_accuracy: 0.8320 - val_loss: 2.5305 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5754 - sparse_categorical_accuracy: 0.8360 - val_loss: 2.4432 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5771 - sparse_categorical_accuracy: 0.8376 - val_loss: 2.4548 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5632 - sparse_categorical_accuracy: 0.8412 - val_loss: 2.4729 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5519 - sparse_categorical_accuracy: 0.8435 - val_loss: 2.4530 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5489 - sparse_categorical_accuracy: 0.8420 - val_loss: 2.4116 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5506 - sparse_categorical_accuracy: 0.8447 - val_loss: 2.4088 - val_sparse_categorical_accuracy: 0.0975\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5508 - sparse_categorical_accuracy: 0.8432 - val_loss: 2.3787 - val_sparse_categorical_accuracy: 0.0975\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(28,28,1))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_mlp')\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "metrics = [tf.keras.metrics.sparse_categorical_accuracy]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-brick",
   "metadata": {},
   "source": [
    "## Vanilla MLP with normalization\n",
    "\n",
    "With normalization the accuracy is almost perfect (0.99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "common-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6762 - sparse_categorical_accuracy: 0.7865 - val_loss: 0.1501 - val_sparse_categorical_accuracy: 0.9540\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2325 - sparse_categorical_accuracy: 0.9321 - val_loss: 0.1068 - val_sparse_categorical_accuracy: 0.9679\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1830 - sparse_categorical_accuracy: 0.9464 - val_loss: 0.0796 - val_sparse_categorical_accuracy: 0.9760\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1562 - sparse_categorical_accuracy: 0.9521 - val_loss: 0.0718 - val_sparse_categorical_accuracy: 0.9786\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1441 - sparse_categorical_accuracy: 0.9558 - val_loss: 0.0626 - val_sparse_categorical_accuracy: 0.9809\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1305 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.0589 - val_sparse_categorical_accuracy: 0.9815\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.0500 - val_sparse_categorical_accuracy: 0.9845\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1155 - sparse_categorical_accuracy: 0.9649 - val_loss: 0.0431 - val_sparse_categorical_accuracy: 0.9864\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1165 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.0421 - val_sparse_categorical_accuracy: 0.9870\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1120 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.0379 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1044 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9886\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1052 - sparse_categorical_accuracy: 0.9688 - val_loss: 0.0389 - val_sparse_categorical_accuracy: 0.9876\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0970 - sparse_categorical_accuracy: 0.9700 - val_loss: 0.0346 - val_sparse_categorical_accuracy: 0.9885\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0940 - sparse_categorical_accuracy: 0.9706 - val_loss: 0.0295 - val_sparse_categorical_accuracy: 0.9909\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.0290 - val_sparse_categorical_accuracy: 0.9908\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0896 - sparse_categorical_accuracy: 0.9719 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9913\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9746 - val_loss: 0.0299 - val_sparse_categorical_accuracy: 0.9911\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0850 - sparse_categorical_accuracy: 0.9745 - val_loss: 0.0264 - val_sparse_categorical_accuracy: 0.9923\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0888 - sparse_categorical_accuracy: 0.9733 - val_loss: 0.0255 - val_sparse_categorical_accuracy: 0.9921\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0781 - sparse_categorical_accuracy: 0.9753 - val_loss: 0.0242 - val_sparse_categorical_accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(28,28,1))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_mlp')\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "metrics = [tf.keras.metrics.sparse_categorical_accuracy]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(x_train_norm, y_train, epochs=20, validation_data=(x_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-sample",
   "metadata": {},
   "source": [
    "## Convolutional NN\n",
    "\n",
    "Using CNNs I can get past the 0.99 barrier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "solid-logistics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 99s 53ms/step - loss: 0.3469 - sparse_categorical_accuracy: 0.8856 - val_loss: 0.1070 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 100s 53ms/step - loss: 0.0489 - sparse_categorical_accuracy: 0.9841 - val_loss: 0.0323 - val_sparse_categorical_accuracy: 0.9896\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 103s 55ms/step - loss: 0.0314 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0219 - val_sparse_categorical_accuracy: 0.9929\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0238 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0204 - val_sparse_categorical_accuracy: 0.9937\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0204 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0124 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9948 - val_loss: 0.0090 - val_sparse_categorical_accuracy: 0.9973\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0139 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0069 - val_sparse_categorical_accuracy: 0.9978\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0097 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.0062 - val_sparse_categorical_accuracy: 0.9980\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0121 - val_sparse_categorical_accuracy: 0.9963\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0094 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0067 - val_sparse_categorical_accuracy: 0.9979\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9979 - val_loss: 0.0075 - val_sparse_categorical_accuracy: 0.9977\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 103s 55ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0023 - val_sparse_categorical_accuracy: 0.9994\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0062 - sparse_categorical_accuracy: 0.9982 - val_loss: 0.0058 - val_sparse_categorical_accuracy: 0.9981\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0065 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 0.9983\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0092 - val_sparse_categorical_accuracy: 0.9972\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0048 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0043 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0039 - val_sparse_categorical_accuracy: 0.9988\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0051 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0034 - val_sparse_categorical_accuracy: 0.9989\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0036 - sparse_categorical_accuracy: 0.9990 - val_loss: 0.0032 - val_sparse_categorical_accuracy: 0.9990\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 98s 52ms/step - loss: 0.0054 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0016 - val_sparse_categorical_accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(28,28,1))\n",
    "x = tf.keras.layers.Conv2D(filters=128, kernel_size=5, padding='same', activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=3, data_format='channels_last')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=56, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=3, data_format='channels_last')(x)\n",
    "x = tf.keras.layers.Conv2D(filters=28, kernel_size=5, padding='same', activation='relu')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=3, data_format='channels_last')(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='mnist_cnn')\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "metrics = [tf.keras.metrics.sparse_categorical_accuracy]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(x_train_norm, y_train, epochs=20, validation_data=(x_test_norm, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-suspect",
   "metadata": {},
   "source": [
    "## XGBoost classifier without normalization\n",
    "\n",
    "XGBoost is completely insensitive to normalization and gives numerically identical results with or without. It performs a bit worse than the MLP but it is also not finely tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mature-tribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:17:57] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softmax' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Test accuracy: 0.95865\n",
      "Train accuracy: 0.95865\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "d_train = xgb.DMatrix(x_train.reshape(x_train.shape[0],-1), y_train)\n",
    "d_test = xgb.DMatrix(x_test.reshape(x_test.shape[0],-1), y_train)\n",
    "xgb_params = {'max_depth':6,\n",
    "              'min_child_weight':6,\n",
    "              'subsample':0.8,\n",
    "              'colsample_bytree':0.8,\n",
    "              'gamma':0,\n",
    "              'learning_rate':0.01,\n",
    "              'tree_method':'hist',\n",
    "              'objective':'multi:softmax',\n",
    "              'num_class': 10,\n",
    "             }\n",
    "model = xgb.train(xgb_params, d_train, num_boost_round=250)\n",
    "y_test_pred = model.predict(d_test)\n",
    "y_train_pred = model.predict(d_train)\n",
    "print('Test accuracy:', accuracy_score(y_test_pred, y_test))\n",
    "print('Train accuracy:', accuracy_score(y_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-vanilla",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
