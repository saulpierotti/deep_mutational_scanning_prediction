{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daily-belize",
   "metadata": {},
   "source": [
    "# RawMSA test implementation\n",
    "\n",
    "In this notebook I test my implementation of the rawMSA net for the prediction of secondary structure and solvent accessibility (its original tasks). I will in other notebooks adapt the net for the prediction of variant effect. I am using the very limited grey2018 dataset with 9 proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "veterinary-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import pandas as pd; pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_full = pd.read_csv('../dataset/gray2018/dmsTraining_2017-02-20.csv')\n",
    "df = df_full\n",
    "\n",
    "# some of the studies in the training set were excluded from training in the original paper\n",
    "excluded_studies = ['Brca1_E3', 'Brca1_Y2H', 'E3_ligase']\n",
    "for study in excluded_studies:\n",
    "    df = df[df['dms_id'] != study]\n",
    "    \n",
    "# many of the columns are not needed for this task\n",
    "df = df[['uniprot_id', 'position', 'dssp_sec_str', 'accessibility']]\n",
    "\n",
    "# for this task I don't care about different mutations in the same position, I want each position only once\n",
    "# I can drop duplicates since I removed all the columns relating to the kind of mutatiion\n",
    "df = df.drop_duplicates()\n",
    "    \n",
    "# boolean vectors to slice the rows which have a value\n",
    "has_dssp = df['dssp_sec_str'].notna()\n",
    "has_accessibility = df['accessibility'].notna()\n",
    "\n",
    "df_dssp = df[has_dssp]\n",
    "df_accessibility = df[has_accessibility]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-receptor",
   "metadata": {},
   "source": [
    "## Extracting the secondary structures and accessibility\n",
    "\n",
    "Many sequence positions have an annotated dssp secondary structure and solvent accessibility in the Gray2018 dataset. Here I extract it and put it into a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "embedded-fossil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../processing/raw_msa/implementation_test_grey2018/accessibility_labels.np.joblib.xz']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_rawmsa_test_path = '../processing/raw_msa/implementation_test_grey2018/'\n",
    "\n",
    "# 3 class dssp mapping reduction\n",
    "ss_d = {\n",
    "        \"H\": \"H\",\n",
    "        \"B\": \"E\",\n",
    "        \"E\": \"E\",\n",
    "        \"G\": \"-\",\n",
    "        \"I\": \"-\",\n",
    "        \"T\": \"-\",\n",
    "        \"S\": \"-\",\n",
    "        \".\": \"-\", # should be a space but it was replaced by . in the grey dataset\n",
    "    }\n",
    "# need to code each class with an integer\n",
    "ss_sparse = {\n",
    "        \"H\": 0,\n",
    "        \"E\": 1,\n",
    "        \"-\": 2,\n",
    "    }\n",
    "ss_list = [ss_sparse[ss_d[el]] for el in df['dssp_sec_str'][has_dssp]]\n",
    "\n",
    "# creating and saving the label arrays\n",
    "ss_array = np.array(ss_list).reshape(-1,1)\n",
    "accessibility_array = np.array(df['accessibility'][has_accessibility]).reshape(-1,1)\n",
    "joblib.dump(ss_array, out_rawmsa_test_path + 'ss_labels.np.joblib.xz')\n",
    "joblib.dump(accessibility_array, out_rawmsa_test_path + 'accessibility_labels.np.joblib.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-burns",
   "metadata": {},
   "source": [
    "## Obtaining sliding windows\n",
    "\n",
    "For each of the position in the msa of the proteins in the dataset, I obtain the relative sliding window padded with 0 if needed at the right, left or bottom. I put it in a lookup table for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "rubber-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 31\n",
    "msa_depth = 500\n",
    "in_msa_path = '../processing/gray2018/msa_vectors/'\n",
    "basename_list = '../processing/gray2018/input_list.txt'\n",
    "\n",
    "with open(basename_list) as handle:\n",
    "    sliding_windows = {}\n",
    "    for line in handle:\n",
    "        basename = line.rstrip()\n",
    "        msa_vec = joblib.load(in_msa_path + basename + '.npy.joblib.xz')[:msa_depth]\n",
    "        windows_list = []\n",
    "        for i, _ in enumerate(msa_vec.T):\n",
    "            upper = i + ((window_size - 1)//2) + 1\n",
    "            lower = i - ((window_size - 1)//2)\n",
    "            pad_lower, pad_upper = 0, 0\n",
    "            if lower < 0:\n",
    "                pad_lower = - lower\n",
    "                lower = 0\n",
    "            if upper > len(msa_vec.T):\n",
    "                pad_upper = upper - len(msa_vec.T)\n",
    "                # no need to reset upper since numpy allows indeces exceeding len\n",
    "            curr_window_unpadded = msa_vec[:, lower:upper]\n",
    "            # this is for the vertical padding if there are not enough sequences in the msa\n",
    "            pad_vertical = 0\n",
    "            if len(msa_vec) < msa_depth:\n",
    "                pad_vertical = msa_depth - len(msa_vec)\n",
    "            # 0 is a special padding value for the keras embedding layer\n",
    "            curr_window = np.pad(curr_window_unpadded, ((0,pad_vertical),(pad_lower,pad_upper)), mode='constant', constant_values = 0)\n",
    "            assert curr_window.shape == (msa_depth, window_size)\n",
    "            windows_list.append(curr_window)\n",
    "        sliding_windows[basename] = np.array(windows_list)\n",
    "        assert sliding_windows[basename].shape == (len(msa_vec.T), msa_depth, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-implement",
   "metadata": {},
   "source": [
    "## Map the sliding windows to the training data\n",
    "\n",
    "For each training point, I extract the relative sliding window and I put it into a vector that can be used for training together with the ss and accessibility vectors. I save the output to numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "pacific-neighbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../processing/raw_msa/implementation_test_grey2018/accessibility_sliding_window.np.joblib.xz']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_windows(sliding_windows, df):\n",
    "    # the first element of iterrows is the index\n",
    "    windows = []\n",
    "    for _, row in df.iterrows():\n",
    "        # I remove 1 to position since the index starts from 0 but the position from 1\n",
    "        curr_window = sliding_windows[row['uniprot_id']][row['position']-1]\n",
    "        windows.append(curr_window)\n",
    "    windows_vec = np.array(windows)\n",
    "    assert windows_vec.shape[0] == len(df)\n",
    "    return windows_vec\n",
    "\n",
    "dssp_windows = map_windows(sliding_windows, df_dssp)\n",
    "accessibility_windows = map_windows(sliding_windows, df_accessibility)\n",
    "\n",
    "joblib.dump(dssp_windows, '../processing/raw_msa/implementation_test_grey2018/ss_sliding_window.np.joblib.xz')\n",
    "joblib.dump(accessibility_windows, '../processing/raw_msa/implementation_test_grey2018/accessibility_sliding_window.np.joblib.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-trainer",
   "metadata": {},
   "source": [
    "## Deep learning\n",
    "\n",
    "Here general operation that are common to all the deep learning steps, and I show tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tight-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "import json\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helpful-december",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 227810), started 0:24:31 ago. (Use '!kill 227810' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4d6172057ea44441\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4d6172057ea44441\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-ancient",
   "metadata": {},
   "source": [
    "### SS network\n",
    "\n",
    "Here I create the rawMSA network for secondary structure prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instructional-vitamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my input is of shape LY where L is the size of the sliding window (31 here) and Y is the depth (500 here)\n",
    "# In this original implementation the input is a vector, so I presume that they first flatten the msa to give as input\n",
    "# this is not really declared anywhere but if I give in input a None,None shape, then the reshape removes a dimension!\n",
    "# the dimensions declared here do not include the batch size, which is added as a None first dimension automatically\n",
    "# note that this is a tensor shape, not an input layer\n",
    "# for the functional API is recommended in place of InputLayer\n",
    "window_size = 31\n",
    "msa_depth = 500\n",
    "embedding_dim = 14\n",
    "inputs = tf.keras.Input(shape=(msa_depth, window_size))\n",
    "# I flatten the input for the embedding layer\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "# this is the embedding layer\n",
    "# 26 is the number of residues (20 standard, the additional characthers XBZU, and - for gaps)\n",
    "# 14 is the dimensionality of the embedding used\n",
    "# I am avoiding here to specify many parameters, if the defaults differ from what is in the rawMSA paper I will adjust it later\n",
    "# x is the running variable that I use to connect the layers\n",
    "# the shape after the embedding is batch,LY,E\n",
    "x = tf.keras.layers.Embedding(input_dim=26, output_dim=embedding_dim, mask_zero=True)(x)\n",
    "# I reshape to undo the initial flattening of the input, so I separate the L and Y dimensions (length and alignment depth)\n",
    "# my shape now is batch,L,Y,E\n",
    "x = tf.keras.layers.Reshape((-1,msa_depth,embedding_dim))(x)\n",
    "# for the ss_rsa netowork there is a single convolution on the embedded input\n",
    "# I use a number of filters equal to the embedding dimensionality\n",
    "# the filter is still of width 1 but much longer than the one used for the cmap network\n",
    "# the activation is linear since there is a separate relu activation layer\n",
    "# the dimensions do not change after this layers but from now on I will refer to the third axis as F and not E\n",
    "x = tf.keras.layers.Conv2D(embedding_dim, [1,10], activation='relu', padding='same', data_format='channels_last')(x)\n",
    "# this max pooling layer uses a really long pooling but always of 1 column width\n",
    "# this compresses the Y dimension\n",
    "# the shape goes from batch,L,Y,F to batch,L,S,F, where S=Y/n is 500/20=25\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=[1,20], data_format='channels_last')(x)\n",
    "# I remove 1 axis by concatenating S and F to SF where SF=25*14=350\n",
    "# the new shape is batch,L,SF\n",
    "x = tf.keras.layers.Reshape((-1,embedding_dim*(msa_depth//20)))(x)\n",
    "# the last part of the network involves bidirectional LSTM units\n",
    "# the sequence is read with recurrent units in both direction and then the results are averaged (merge_mode='ave')\n",
    "# I want in output a full sequence and not only the last output of the recurrence\n",
    "# It uses tanh activation in output but hard sigmoid between the recurrent units\n",
    "# the hard sigmoid is a piecewise function with similar behaviour to the sigmoid\n",
    "# it is easier to compute at the cost of precision\n",
    "# the initializtion default is glorot while the authors used variance scaling\n",
    "# I leave it glorot for now since I believe it to be due to the keras version default\n",
    "# the lstm_brnn + droput combination is applied twice\n",
    "# this loop does not alter the shape (it is a seq-to-seq lstm) which remains batch,L,SF=350\n",
    "for _ in range(2):\n",
    "    lstm_layer = tf.keras.layers.LSTM(embedding_dim*(msa_depth//20), return_sequences=True, recurrent_activation='hard_sigmoid')\n",
    "    x = tf.keras.layers.Bidirectional(lstm_layer, merge_mode='ave')(x)\n",
    "    # dropout layer with a 0.5 probability of dropping a connection\n",
    "    # non-dropped input are rescaled so to maintain the some over the inputs\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "# the L and SF axes are collapsed, giving dimension batch,LSF\n",
    "# I am concatenating the sliding window dimension L with the depth/channel dimension SF\n",
    "x = tf.keras.layers.Flatten(data_format='channels_last')(x)\n",
    "# now 2 dense layers with dropout to convert all the information to 3 values, the prediction for the\n",
    "# ss of the central residue of the sliding window\n",
    "x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(20, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "# finally softmax with 3 output units for the 3 ss classes for the central residue\n",
    "outputs = tf.keras.layers.Dense(3, activation='softmax')(x)\n",
    "# I generate the model linking inputs and outputs\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='ss_recreated')\n",
    "# the optimizer is RMSProp with a tweaked epsilon\n",
    "optimizer = tf.keras.optimizers.RMSprop(epsilon=1e-9)\n",
    "# the loss is sparse_categorical_crossentropy (a function), not the class SparseCategoricalCrossentropy\n",
    "# when using the class it needs to be called first\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "q3_accuracy = sklearn.metrics.accuracy_score\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "separated-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 25s 763ms/step - loss: 1.3153 - sparse_categorical_accuracy: 0.4577 - val_loss: 1.1588 - val_sparse_categorical_accuracy: 0.1632\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 16s 679ms/step - loss: 1.0793 - sparse_categorical_accuracy: 0.4591 - val_loss: 1.1135 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 17s 723ms/step - loss: 1.0834 - sparse_categorical_accuracy: 0.4172 - val_loss: 1.1301 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 16s 669ms/step - loss: 1.0746 - sparse_categorical_accuracy: 0.4445 - val_loss: 1.1170 - val_sparse_categorical_accuracy: 0.4053\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 16s 672ms/step - loss: 1.0769 - sparse_categorical_accuracy: 0.4261 - val_loss: 1.1121 - val_sparse_categorical_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 16s 672ms/step - loss: 1.1225 - sparse_categorical_accuracy: 0.4279 - val_loss: 1.0899 - val_sparse_categorical_accuracy: 0.4263\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 16s 682ms/step - loss: 1.0143 - sparse_categorical_accuracy: 0.5042 - val_loss: 0.9902 - val_sparse_categorical_accuracy: 0.4474\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 16s 688ms/step - loss: 0.9232 - sparse_categorical_accuracy: 0.5342 - val_loss: 1.0491 - val_sparse_categorical_accuracy: 0.4632\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 17s 696ms/step - loss: 0.9138 - sparse_categorical_accuracy: 0.5150 - val_loss: 1.4400 - val_sparse_categorical_accuracy: 0.3579\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 16s 679ms/step - loss: 0.8829 - sparse_categorical_accuracy: 0.5586 - val_loss: 1.1994 - val_sparse_categorical_accuracy: 0.3789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff4951ded30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input selection\n",
    "x = joblib.load('../processing/raw_msa/implementation_test_grey2018/ss_sliding_window.np.joblib.xz')\n",
    "y = joblib.load('../processing/raw_msa/implementation_test_grey2018/ss_labels.np.joblib.xz')\n",
    "#np.random.shuffle(y)\n",
    "\n",
    "# tensorflow logging\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# fit the model\n",
    "model.fit(x, y, epochs=10, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-going",
   "metadata": {},
   "source": [
    "### RSA network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fallen-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar to ss network but with different embedding dim, conv2d kernel size, max_pool size, droput\n",
    "\n",
    "window_size = 31\n",
    "msa_depth = 500\n",
    "embedding_dim = 28\n",
    "\n",
    "inputs = tf.keras.Input(shape=(msa_depth, window_size))\n",
    "x = tf.keras.layers.Flatten()(inputs)\n",
    "x = tf.keras.layers.Embedding(input_dim=26, output_dim=embedding_dim, mask_zero=True)(x)\n",
    "x = tf.keras.layers.Reshape((-1,msa_depth,embedding_dim))(x)\n",
    "x = tf.keras.layers.Conv2D(embedding_dim, [1,20], activation='relu', padding='same', data_format='channels_last')(x)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=[1,30], data_format='channels_last')(x)\n",
    "x = tf.keras.layers.Reshape((-1,embedding_dim*(msa_depth//30)))(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    lstm_layer = tf.keras.layers.LSTM(embedding_dim*(msa_depth//30), return_sequences=True, recurrent_activation='hard_sigmoid')\n",
    "    x = tf.keras.layers.Bidirectional(lstm_layer, merge_mode='ave')(x)\n",
    "    x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "x = tf.keras.layers.Flatten(data_format='channels_last')(x)\n",
    "x = tf.keras.layers.Dense(50)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(20)(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='rsa_recreated')\n",
    "optimizer = tf.keras.optimizers.RMSprop(epsilon=1e-9)\n",
    "loss = tf.keras.losses.sparse_categorical_crossentropy\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['sparse_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "japanese-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "24/24 [==============================] - 43s 2s/step - loss: 1.7896 - sparse_categorical_accuracy: 0.5153 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.4892\n",
      "Epoch 2/10\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.7004 - sparse_categorical_accuracy: 0.4990 - val_loss: 0.7966 - val_sparse_categorical_accuracy: 0.5108\n",
      "Epoch 3/10\n",
      "24/24 [==============================] - 36s 1s/step - loss: 0.7303 - sparse_categorical_accuracy: 0.5165 - val_loss: 0.7142 - val_sparse_categorical_accuracy: 0.5108\n",
      "Epoch 4/10\n",
      "24/24 [==============================] - 35s 1s/step - loss: 0.6966 - sparse_categorical_accuracy: 0.5419 - val_loss: 0.7523 - val_sparse_categorical_accuracy: 0.4892\n",
      "Epoch 5/10\n",
      "24/24 [==============================] - 36s 2s/step - loss: 0.6953 - sparse_categorical_accuracy: 0.5657 - val_loss: 0.6945 - val_sparse_categorical_accuracy: 0.5108\n",
      "Epoch 6/10\n",
      "24/24 [==============================] - 36s 1s/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5544 - val_loss: 0.7152 - val_sparse_categorical_accuracy: 0.5108\n",
      "Epoch 7/10\n",
      "24/24 [==============================] - 38s 2s/step - loss: 0.6839 - sparse_categorical_accuracy: 0.5620 - val_loss: 0.6996 - val_sparse_categorical_accuracy: 0.5161\n",
      "Epoch 8/10\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.6710 - sparse_categorical_accuracy: 0.5643 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.5484\n",
      "Epoch 9/10\n",
      "24/24 [==============================] - 36s 2s/step - loss: 0.6766 - sparse_categorical_accuracy: 0.5964 - val_loss: 0.7103 - val_sparse_categorical_accuracy: 0.4892\n",
      "Epoch 10/10\n",
      "24/24 [==============================] - 37s 2s/step - loss: 0.6566 - sparse_categorical_accuracy: 0.5952 - val_loss: 0.7727 - val_sparse_categorical_accuracy: 0.4892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff49bcbe580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input selection\n",
    "x = joblib.load('../processing/raw_msa/implementation_test_grey2018/accessibility_sliding_window.np.joblib.xz')\n",
    "y_cont = joblib.load('../processing/raw_msa/implementation_test_grey2018/accessibility_labels.np.joblib.xz')\n",
    "y = np.array([1 if el > 0.3 else 0 for el in y_cont])\n",
    "#np.random.shuffle(y)\n",
    "\n",
    "# tensorflow logging\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# fit the model\n",
    "model.fit(x, y, epochs=10, validation_split=0.2, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
