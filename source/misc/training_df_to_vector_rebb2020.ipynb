{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lightweight-salon",
   "metadata": {},
   "source": [
    "# Training dataframe to vectors Rebb2020\n",
    "This notebook summarizes the complete training dataframe in numpy arrays that can be directly used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "delayed-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "out_path = '../processing/training_set/'\n",
    "df = pd.read_csv('../dataset/Reeb2020/SetAll_only_deleterious.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-annotation",
   "metadata": {},
   "source": [
    "Some entries have a non-defined values for the fields `ToAA`. Since they are not many I remove them. These entries are marked with the `*` charachter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "electrical-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(df[df['FromAA'] == '*']))\n",
    "print(len(df[df['ToAA'] == '*']))\n",
    "\n",
    "df_clean = df[df['FromAA'] != '*'][df['ToAA'] != '*']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-portfolio",
   "metadata": {},
   "source": [
    "I create a (40, 1) vector for each mutation coding FromAA and ToAA as one-hot concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "naval-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45352, 40)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seq_to_one_hot(sequence):\n",
    "    # the aa order is the same used in psiblast pssm\n",
    "    aa_tuple = tuple('ARNDCQEGHILKMFPSTWYV')\n",
    "    growing_arr = []\n",
    "    for char in sequence:\n",
    "        curr_row = [1 if char == aa else 0 for _,aa in enumerate(aa_tuple)]\n",
    "        growing_arr.append(curr_row)\n",
    "    one_hot_vec = np.array(growing_arr)\n",
    "    assert one_hot_vec.sum(axis=1).all() == 1\n",
    "    assert one_hot_vec.sum(axis=1).sum() == len(sequence)\n",
    "    assert one_hot_vec.all() in (0,1)\n",
    "    return one_hot_vec\n",
    "\n",
    "from_aa_vec = seq_to_one_hot(df_clean['FromAA'])\n",
    "to_aa_vec = seq_to_one_hot(df_clean['ToAA'])\n",
    "mutations_two_hot = np.concatenate((from_aa_vec, to_aa_vec), axis=1)\n",
    "np.save(out_path + 'mutations_two_hot.npy', mutations_two_hot)\n",
    "mutations_two_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-graph",
   "metadata": {},
   "source": [
    "I save in an array also the position of the mutation along the sequence (0-indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "surprising-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45352, 1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_vec = np.array(df_clean['Position(1-indexed)']).reshape(-1,1).astype(int)\n",
    "# the dataset was 1-indexed and now I make it 0-indexed\n",
    "assert positions_vec.all() >= 1\n",
    "positions_vec = positions_vec - 1\n",
    "assert positions_vec.all() >= 0\n",
    "np.save(out_path + 'position_vec.npy', positions_vec)\n",
    "positions_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-alarm",
   "metadata": {},
   "source": [
    "I save an array of strings containing the source dataset for each mutation. I replace for each instance the `/` charachter with `-` so to be equal to the respective filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "reliable-council",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45352, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['DatasetId_clean'] = df_clean['DatasetId'].str.replace('/', '-')\n",
    "dataset_vec = np.array(df_clean['DatasetId_clean']).reshape(-1,1).astype(str)\n",
    "np.save(out_path + 'dataset_vec.npy', dataset_vec)\n",
    "dataset_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-reading",
   "metadata": {},
   "source": [
    "Finally I extract the target value, the normalized score for each mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "violent-frost",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45352, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_vec = np.array(df_clean['NormalizedScore']).reshape(-1,1)\n",
    "np.save(out_path + 'norm_score.npy', score_vec)\n",
    "score_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-acoustic",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
